import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import fbeta_score, accuracy_score,  make_scorer
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from sklearn.linear_model import LogisticRegression
from sklearn import svm
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from collections import defaultdict
import matplotlib.pyplot as plt
import plotly.express as px


SEED = 42

def seed_everything(seed = 42):
    import random, os
    import numpy as np

    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)

seed_everything(SEED)


train_df = pd.read_csv('../imported/data/Train.csv')
test_df = pd.read_csv('../imported/data/Test.csv')
sample_sub = pd.read_csv('../imported/data/Sample_submission.csv')


train_df.info()


missing_values_info = train_df.isnull().sum() / len(train_df)


missing_values_info_df = pd.DataFrame()
missing_values_info_df['features'] = missing_values_info.index
missing_values_info_df['missing_values'] = missing_values_info.values


px.bar(x='missing_values', y='features', data_frame=missing_values_info_df, title='Missing values in %', color='features')


selected_features = missing_values_info_df[missing_values_info_df['missing_values']>0]['features'].values


for col in selected_features:
    train_df[col] = train_df[col].fillna('unknown')
    test_df[col] = test_df[col].fillna('unknown')


train_df.info()
test_df.info()


train_df['TARGET'].describe()


income_greater_equal_to_50k = train_df['TARGET'].sum()
income_less_than_50k = train_df.shape[0] - income_greater_equal_to_50k
print(income_greater_equal_to_50k, income_less_than_50k)
print("% of people with salary greater than or equal to 50k", (100*income_greater_equal_to_50k/train_df.shape[0]).round(2), "%")


for col in train_df.select_dtypes('object'):
    if col != 'ID':
        le = LabelEncoder()
        train_df[col] = le.fit_transform(train_df[col])
        test_df[col] = le.transform(test_df[col])


train_df.info()
test_df.info()


import matplotlib.pyplot as plt
import seaborn as sns
plt.style.use('fivethirtyeight')
import warnings
warnings.filterwarnings('ignore')
get_ipython().run_line_magic("matplotlib", " inline")

sns.heatmap(train_df.corr(),annot=False,cmap='RdYlGn',linewidths=0.2,annot_kws={'size':20})
fig=plt.gcf()
fig.set_size_inches(18,15)
plt.xticks(fontsize=14)
plt.yticks(fontsize=14)
plt.show()


import matplotlib.pyplot as plt
f,ax=plt.subplots(1,1,figsize=(25,12))
model=RandomForestClassifier(random_state=SEED)
model.fit(X_train,y_train)
feat_importances = pd.Series(model.feature_importances_, index=X.columns)
feat_importances.nlargest(25).sort_values(ascending=True).plot(kind='barh')
# pd.Series(model.feature_importances_,X.columns).sort_values(ascending=True).plot.barh(width=0.8,ax=ax[0,0])
# ax[0,0].set_title('Feature Importance in Random Forests')


selected_columns = feat_importances.nlargest(25).index
selected_columns = selected_columns.tolist()
selected_columns.append('ID')
selected_columns.append('TARGET')
selected_columns
train_df = train_df[selected_columns]


X = train_df.drop(columns=['ID','TARGET'])
print(X.shape)
y = train_df.TARGET
print(y.shape)


X_train, X_valid, y_train, y_valid = train_test_split(X,y,
                                                        test_size=0.2, 
                                                        stratify=y, 
                                                        random_state=SEED)


X_train.shape, y_train.shape


y_train.value_counts()/len(y_train)


X_valid.shape, y_valid.shape


y_valid.value_counts()/len(y_valid)


def train_model(classifier, input_x, input_y):
    clf = classifier.fit(input_x, input_y)
    return clf

def evaluate_model(classifier, validation_x, validation_y, eval_metrics=fbeta_score):
    ypred = classifier.predict(validation_x)
    return ypred, eval_metrics(validation_y, ypred, beta=0.5)



classifiers = {
    'logistic_regression' : LogisticRegression(solver='liblinear', random_state=SEED),
    'decision_tree' : DecisionTreeClassifier(random_state=SEED),
    'random_forest': RandomForestClassifier(random_state=SEED),
    # 'linear_svm': svm.SVC(kernel='linear',random_state=SEED),
    'naive_bayes': GaussianNB(),
    'k_neighbors': KNeighborsClassifier()
    }


trained_models = {}
for classifier_name, classifier in classifiers.items():
    print("Started for: ", classifier)
    model = train_model(classifier, X_train, y_train)
    ypred, validation_score = evaluate_model(model, X_valid, y_valid)
    print("Done for: ", classifier)
    trained_models[classifier_name] = {'model': model, 'f1_score': validation_score}


validation_results = defaultdict(list)
for k,v in trained_models.items():
    validation_results['classifier_name'].append(k)
    validation_results['f1_score'].append(v['f1_score'])
validation_results = pd.DataFrame(validation_results)


validation_results


px.bar(x='f1_score', y='classifier_name', data_frame=validation_results, color="classifier_name", title='Algorithm Performance Comparison')


a_index=list(range(1,21))
a=pd.Series()
x=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]
for i in list(range(1,21)):
    print("Started For i =", i)
    model=KNeighborsClassifier(n_neighbors=i) 
    model.fit(X_train,y_train)
    prediction=model.predict(X_valid)
    a=a.append(pd.Series(accuracy_score(prediction,y_valid)))
plt.plot(a_index, a)
plt.xticks(x)
fig=plt.gcf()
fig.set_size_inches(12,6)
plt.show()
print('Accuracies for different values of n are:',a.values,'with the max value as ',a.values.max())


n_estimators=range(100,1000,100)
hyper={'n_estimators':n_estimators}
ftwo_scorer = make_scorer(fbeta_score, beta=0.5)
gd=GridSearchCV(estimator=RandomForestClassifier(random_state=SEED),param_grid=hyper,scoring=ftwo_scorer, verbose=5,n_jobs=-1)
gd.fit(X,y)
print(gd.best_score_)
print(gd.best_estimator_)


from sklearn.ensemble import VotingClassifier
ensemble_lin_rbf=VotingClassifier(estimators=[('k_neighbors',KNeighborsClassifier(n_neighbors=10)),
                                              ('random_forest',RandomForestClassifier(random_state=SEED)),
                                              ('logistic_regression',LogisticRegression(solver='liblinear', random_state=SEED)),
                                              ('decision_tree',DecisionTreeClassifier(random_state=SEED)),
                                              ('naive_bayes',GaussianNB())
                                             ], 
                       voting='soft').fit(X_train,y_train)
print('The accuracy for ensembled model is:',ensemble_lin_rbf.score(X_valid,y_valid))


from sklearn.model_selection import cross_val_score
ftwo_scorer = make_scorer(fbeta_score, beta=0.5)
cross=cross_val_score(ensemble_lin_rbf,X,y, cv = 10,scoring = ftwo_scorer, n_jobs=-1)
print('The cross validated score is',cross.mean())


from sklearn.ensemble import BaggingClassifier
model=BaggingClassifier(base_estimator=RandomForestClassifier(random_state=SEED),random_state=SEED,n_estimators=100, verbose=3, n_jobs=-1)
model.fit(X_train,y_train)
prediction=model.predict(X_valid)
print('The accuracy for bagged Decision Tree is:',eval_metrics(y_valid, prediction, beta=0.5))


result=cross_val_score(model,X,y,cv=10,scoring=ftwo_scorer, n_jobs=-1)
print('The cross validated score for bagged Decision Tree is:',result.mean())


test_df = test_df[selected_columns]
test_df.info()
XTest = test_df.drop(columns=['ID'])


ytest_pred = trained_models['random_forest']['model'].predict(XTest)


output = sample_sub.copy()
output['TARGET'] = ytest_pred
output.head()


output['TARGET'].value_counts()/len(output)


output.to_csv('./output/solution.csv', index=False)



